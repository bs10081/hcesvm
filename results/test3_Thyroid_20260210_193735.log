================================================================================
Hierarchical CE-SVM - TEST3 Strategy
Dataset: Thyroid
Timestamp: 2026-02-10 19:37:35
================================================================================

Training data:
  Class 1: 14 samples
  Class 2: 29 samples
  Class 3: 533 samples
  Features: 21

================================================================================
Model Parameters
================================================================================
  C_hyper: 1.0
  epsilon: 0.0001
  M: 1000.0
  time_limit: 1800
  mip_gap: 0.0001
  threads: 0
  verbose: True
  enable_selection: True
  feat_upper_bound: 1000
  feat_lower_bound: 1e-07

================================================================================
Training Hierarchical Classifier - TEST3 Strategy
================================================================================

Test3 Strategy:
  H1: {minority, medium} vs majority
  H2: minority vs medium
  Sample-weighted objective: -(1/s+)·l+ - (1/s-)·l-

============================================================
Training Hierarchical CE-SVM (Strategy: test3)
============================================================
Class 1: 14 samples
Class 2: 29 samples
Class 3: 533 samples
Features: 21

Dynamic Class Roles:
  Majority:  Class 3 (533 samples)
  Medium:    Class 2 (29 samples)
  Minority:  Class 1 (14 samples)

============================================================
Training H1: Class {2, 3} (+1) vs Class 1 (-1)
============================================================
H1 Training samples: 576
  Positive (+1): 562 samples
  Negative (-1): 14 samples
  Class weight: balanced
  Accuracy mode: both

Set parameter TimeLimit to value 1800
Set parameter MIPGap to value 0.0001
Set parameter OutputFlag to value 1
Set parameter Threads to value 0
Gurobi Optimizer version 13.0.1 build v13.0.1rc0 (linux64 - "Ubuntu 24.04.3 LTS")

CPU model: AMD Ryzen 9 9900X 12-Core Processor, instruction set [SSE2|AVX|AVX2|AVX512]
Thread count: 20 physical cores, 20 logical processors, using up to 20 threads

Non-default parameters:
TimeLimit  1800

Optimize a model with 4076 rows, 2370 columns and 16498 nonzeros (Min)
Model fingerprint: 0x421b21a1
Model has 1772 linear objective coefficients
Variable types: 621 continuous, 1749 integer (1749 binary)
Coefficient statistics:
  Matrix range     [1e-07, 1e+03]
  Objective range  [2e-03, 1e+00]
  Bounds range     [1e+00, 1e+00]
  RHS range        [1e+00, 1e+03]

Found heuristic solution: objective 27.9982206
Presolve removed 32 rows and 33 columns
Presolve time: 0.01s
Presolved: 4044 rows, 2337 columns, 16832 nonzeros
Variable types: 33 continuous, 2304 integer (1728 binary)

Root relaxation: objective 1.093493e-02, 661 iterations, 0.01 seconds (0.03 work units)

    Nodes    |    Current Node    |     Objective Bounds      |     Work
 Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time

     0     0    0.01093    0   42   27.99822    0.01093   100%     -    0s
     0     0    2.01392    0   51   27.99822    2.01392  92.8%     -    0s
     0     0    3.00893    0   51   27.99822    3.00893  89.3%     -    0s
     0     0    5.50592    0   57   27.99822    5.50592  80.3%     -    0s
     0     0    6.50093    0   57   27.99822    6.50093  76.8%     -    0s
     0     0   14.65896    0  118   27.99822   14.65896  47.6%     -    0s
     0     0   14.73306    0   69   27.99822   14.73306  47.4%     -    0s
     0     0   14.73380    0   70   27.99822   14.73380  47.4%     -    0s
     0     0   18.91232    0  123   27.99822   18.91232  32.5%     -    0s
     0     0   19.70294    0  122   27.99822   19.70294  29.6%     -    0s
     0     0   19.71900    0  127   27.99822   19.71900  29.6%     -    0s
     0     0   19.72056    0  127   27.99822   19.72056  29.6%     -    0s
     0     0   19.98012    0  120   27.99822   19.98012  28.6%     -    0s
     0     0   19.99761    0  127   27.99822   19.99761  28.6%     -    0s
     0     0   20.00098    0  126   27.99822   20.00098  28.6%     -    0s
     0     0   20.00260    0  128   27.99822   20.00260  28.6%     -    0s
     0     0   20.21916    0  122   27.99822   20.21916  27.8%     -    0s
     0     0   20.23242    0  122   27.99822   20.23242  27.7%     -    0s
     0     0   20.23242    0  123   27.99822   20.23242  27.7%     -    0s
     0     0   20.23242    0  123   27.99822   20.23242  27.7%     -    0s
     0     0   20.24289    0  124   27.99822   20.24289  27.7%     -    0s
     0     0   20.30415    0  123   27.99822   20.30415  27.5%     -    0s
     0     0   20.30606    0  125   27.99822   20.30606  27.5%     -    0s
     0     0   20.30619    0  129   27.99822   20.30619  27.5%     -    0s
     0     0   20.30872    0  124   27.99822   20.30872  27.5%     -    0s
     0     0   20.32687    0  126   27.99822   20.32687  27.4%     -    0s
     0     0   20.33379    0  124   27.99822   20.33379  27.4%     -    0s
     0     0   20.36160    0  127   27.99822   20.36160  27.3%     -    0s
     0     0   20.37100    0  122   27.99822   20.37100  27.2%     -    0s
     0     0   20.37160    0  124   27.99822   20.37160  27.2%     -    0s
     0     0   21.56564    0  115   27.99822   21.56564  23.0%     -    0s
     0     0   22.29113    0  105   27.99822   22.29113  20.4%     -    0s
     0     0   22.55386    0  112   27.99822   22.55386  19.4%     -    0s
     0     0   22.57452    0   98   27.99822   22.57452  19.4%     -    0s
     0     0   22.57548    0  103   27.99822   22.57548  19.4%     -    0s
     0     0   22.84667    0  106   27.99822   22.84667  18.4%     -    0s
     0     0   22.96496    0  110   27.99822   22.96496  18.0%     -    0s
     0     0   22.96926    0  118   27.99822   22.96926  18.0%     -    0s
     0     0   22.99565    0  116   27.99822   22.99565  17.9%     -    0s
     0     0   22.99869    0  121   27.99822   22.99869  17.9%     -    0s
     0     0   23.88877    0  100   27.99822   23.88877  14.7%     -    0s
     0     0   23.91977    0  107   27.99822   23.91977  14.6%     -    0s
     0     0   23.92074    0  110   27.99822   23.92074  14.6%     -    0s
     0     0   23.94042    0  101   27.99822   23.94042  14.5%     -    0s
     0     0   23.95180    0  106   27.99822   23.95180  14.5%     -    0s
     0     0   23.95589    0  105   27.99822   23.95589  14.4%     -    0s
     0     0   23.95752    0  101   27.99822   23.95752  14.4%     -    0s
     0     0   25.36291    0   90   27.99822   25.36291  9.41%     -    0s
     0     0   25.58315    0  106   27.99822   25.58315  8.63%     -    0s
     0     0   25.91803    0   98   27.99822   25.91803  7.43%     -    0s
     0     0   25.99926    0  100   27.99822   25.99926  7.14%     -    0s
     0     0   26.03586    0   90   27.99822   26.03586  7.01%     -    0s
     0     0   26.03681    0   95   27.99822   26.03681  7.01%     -    0s
     0     0   26.67718    0   83   27.99822   26.67718  4.72%     -    0s
     0     0   26.67718    0   42   27.99822   26.67718  4.72%     -    0s
     0     0   26.67718    0   77   27.99822   26.67718  4.72%     -    0s
     0     0   26.67718    0   77   27.99822   26.67718  4.72%     -    0s
     0     0   27.48344    0   58   27.99822   27.48344  1.84%     -    0s
     0     0   27.50998    0    7   27.99822   27.50998  1.74%     -    0s
     0     0   27.97591    0   51   27.99822   27.97591  0.08%     -    0s

Cutting planes:
  Gomory: 8
  Implied bound: 1
  MIR: 25
  Flow cover: 21
  RLT: 3
  Relax-and-lift: 4

Explored 1 nodes (3940 simplex iterations) in 0.54 seconds (1.19 work units)
Thread count was 20 (of 20 available processors)

Solution count 2: 27.9982 27.9982 

Optimal solution found (tolerance 1.00e-04)
Best objective 2.799822064057e+01, best bound 2.799822064057e+01, gap 0.0000%

H1 Solution:
  Weights (w): [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
  Intercept (b): 1.0
  Objective: 27.998221
  Selected features: 21/21
  L1 norm: 0.000000
  Positive accuracy lb: 1.0000
  Negative accuracy lb: 0.0000

============================================================
Training H2: Class 3 (+1) vs Class {1, 2} (-1)
============================================================
H2 Training samples: 576
  Positive (+1): 533 samples
  Negative (-1): 43 samples
  Class weight: balanced
  Accuracy mode: both

Set parameter TimeLimit to value 1800
Set parameter MIPGap to value 0.0001
Set parameter OutputFlag to value 1
Set parameter Threads to value 0
Gurobi Optimizer version 13.0.1 build v13.0.1rc0 (linux64 - "Ubuntu 24.04.3 LTS")

CPU model: AMD Ryzen 9 9900X 12-Core Processor, instruction set [SSE2|AVX|AVX2|AVX512]
Thread count: 20 physical cores, 20 logical processors, using up to 20 threads

Non-default parameters:
TimeLimit  1800

Optimize a model with 4076 rows, 2370 columns and 16498 nonzeros (Min)
Model fingerprint: 0xc03b3fb3
Model has 1772 linear objective coefficients
Variable types: 621 continuous, 1749 integer (1749 binary)
Coefficient statistics:
  Matrix range     [1e-07, 1e+03]
  Objective range  [2e-03, 1e+00]
  Bounds range     [1e+00, 1e+00]
  RHS range        [1e+00, 1e+03]

Found heuristic solution: objective 85.9981238
Presolve removed 29 rows and 30 columns
Presolve time: 0.01s
Presolved: 4047 rows, 2340 columns, 16874 nonzeros
Variable types: 36 continuous, 2304 integer (1728 binary)

Root relaxation: objective 2.329145e-01, 835 iterations, 0.01 seconds (0.05 work units)

    Nodes    |    Current Node    |     Objective Bounds      |     Work
 Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time

     0     0    0.23291    0  129   85.99812    0.23291   100%     -    0s
     0     0    1.23590    0  134   85.99812    1.23590  98.6%     -    0s
     0     0    2.23091    0  134   85.99812    2.23091  97.4%     -    0s
     0     0    4.56457    0  142   85.99812    4.56457  94.7%     -    0s
     0     0    5.55958    0  142   85.99812    5.55958  93.5%     -    0s
     0     0   12.71391    0  154   85.99812   12.71391  85.2%     -    0s
     0     0   24.18591    0  164   85.99812   24.18591  71.9%     -    0s
     0     0   24.18787    0  162   85.99812   24.18787  71.9%     -    0s
     0     0   26.07390    0  363   85.99812   26.07390  69.7%     -    0s
     0     0   26.15475    0  359   85.99812   26.15475  69.6%     -    0s
     0     0   26.43985    0  361   85.99812   26.43985  69.3%     -    0s
     0     0   26.44055    0  364   85.99812   26.44055  69.3%     -    0s
     0     0   35.14327    0  238   85.99812   35.14327  59.1%     -    0s
     0     0   35.70352    0  252   85.99812   35.70352  58.5%     -    0s
     0     0   36.13439    0  255   85.99812   36.13439  58.0%     -    0s
     0     0   36.13939    0  240   85.99812   36.13939  58.0%     -    0s
     0     0   47.44192    0  356   85.99812   47.44192  44.8%     -    0s
     0     0   52.07070    0  354   85.99812   52.07070  39.5%     -    0s
     0     0   52.34311    0  366   85.99812   52.34311  39.1%     -    0s
     0     0   52.53771    0  345   85.99812   52.53771  38.9%     -    0s
     0     0   52.61492    0  349   85.99812   52.61492  38.8%     -    0s
     0     0   52.63650    0  353   85.99812   52.63650  38.8%     -    0s
     0     0   52.63930    0  349   85.99812   52.63930  38.8%     -    0s
     0     0   54.76890    0  328   85.99812   54.76890  36.3%     -    0s
     0     0   55.34238    0  331   85.99812   55.34238  35.6%     -    0s
     0     0   55.68229    0  335   85.99812   55.68229  35.3%     -    0s
     0     0   55.76585    0  339   85.99812   55.76585  35.2%     -    0s
     0     0   55.78929    0  321   85.99812   55.78929  35.1%     -    0s
     0     0   55.86770    0  327   85.99812   55.86770  35.0%     -    0s
     0     0   55.87270    0  329   85.99812   55.87270  35.0%     -    0s
     0     0   57.38987    0  328   85.99812   57.38987  33.3%     -    0s
     0     0   57.77490    0  359   85.99812   57.77490  32.8%     -    0s
     0     0   57.81806    0  353   85.99812   57.81806  32.8%     -    0s
     0     0   57.89500    0  335   85.99812   57.89500  32.7%     -    0s
     0     0   57.93046    0  333   85.99812   57.93046  32.6%     -    0s
     0     0   57.93185    0  334   85.99812   57.93185  32.6%     -    0s
     0     0   58.17164    0  320   85.99812   58.17164  32.4%     -    0s
     0     0   58.32123    0  322   85.99812   58.32123  32.2%     -    0s
     0     0   58.61726    0  332   85.99812   58.61726  31.8%     -    0s
     0     0   58.69033    0  325   85.99812   58.69033  31.8%     -    0s
     0     0   58.69271    0  326   85.99812   58.69271  31.8%     -    0s
     0     0   58.86832    0  336   85.99812   58.86832  31.5%     -    0s
     0     0   58.94576    0  347   85.99812   58.94576  31.5%     -    0s
     0     0   58.94576    0  334   85.99812   58.94576  31.5%     -    0s
     0     0   58.94576    0  343   85.99812   58.94576  31.5%     -    0s
     0     0   58.95927    0  331   85.99812   58.95927  31.4%     -    0s
     0     0   58.96360    0  329   85.99812   58.96360  31.4%     -    0s
     0     0   70.02291    0  314   85.99812   70.02291  18.6%     -    0s
     0     0   71.07505    0  338   85.99812   71.07505  17.4%     -    0s
     0     0   71.25953    0  319   85.99812   71.25953  17.1%     -    0s
     0     0   71.28396    0  327   85.99812   71.28396  17.1%     -    0s
     0     0   71.29274    0  329   85.99812   71.29274  17.1%     -    0s
     0     0   71.40373    0  340   85.99812   71.40373  17.0%     -    0s
     0     0   71.42901    0  340   85.99812   71.42901  16.9%     -    0s
     0     0   71.56908    0  337   85.99812   71.56908  16.8%     -    0s
     0     0   71.60456    0  325   85.99812   71.60456  16.7%     -    0s
     0     0   73.07410    0  315   85.99812   73.07410  15.0%     -    0s
     0     0   73.21193    0  325   85.99812   73.21193  14.9%     -    0s
     0     0   73.26431    0  326   85.99812   73.26431  14.8%     -    0s
     0     0   73.27099    0  319   85.99812   73.27099  14.8%     -    0s
     0     0   73.28095    0  326   85.99812   73.28095  14.8%     -    0s
     0     0   73.29589    0  336   85.99812   73.29589  14.8%     -    0s
     0     0   73.30455    0  334   85.99812   73.30455  14.8%     -    0s
     0     0   73.31441    0  337   85.99812   73.31441  14.7%     -    0s
     0     0   73.32808    0  328   85.99812   73.32808  14.7%     -    0s
     0     0   73.33518    0  328   85.99812   73.33518  14.7%     -    0s
     0     2   73.33579    0  328   85.99812   73.33579  14.7%     -    0s
  9992  1280   85.43504   19 1566   85.99812   82.62508  3.92%   145    5s

Cutting planes:
  Gomory: 78
  Cover: 1
  Implied bound: 206
  Dual implied bound: 3
  MIR: 310
  Flow cover: 492
  Inf proof: 9
  Relax-and-lift: 15

Explored 13663 nodes (2003213 simplex iterations) in 6.23 seconds (16.34 work units)
Thread count was 20 (of 20 available processors)

Solution count 2: 85.9981 85.9981 

Optimal solution found (tolerance 1.00e-04)
Best objective 8.599812382739e+01, best bound 8.599812382739e+01, gap 0.0000%

H2 Solution:
  Weights (w): [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
  Intercept (b): 1.0
  Objective: 85.998124
  Selected features: 21/21
  L1 norm: 0.000000
  Positive accuracy lb: 1.0000
  Negative accuracy lb: 0.0000

============================================================
Training Complete!
============================================================

Training completed in: 0:00:06.865563

================================================================================
Model Summary
================================================================================
Status: fitted
Strategy: test3
Features: 21

Class Roles:
  Majority: Class 3
  Medium:   Class 2
  Minority: Class 1

Classifier 1 (H1): Class {2, 3} vs Class 1
  Objective: 27.998221
  Selected Features: 21/21
  L1 Norm: 0.000000

Classifier 2 (H2): Class 3 vs Class {1, 2}
  Objective: 85.998124
  Selected Features: 21/21
  L1 Norm: 0.000000

================================================================================
H1 Complete Weights and Bias
================================================================================
Description: Class {2, 3} vs Class 1

Intercept (b): 1.0000000000

Weight vector (w) - 21 features:
  w[0] = 0.0000000000
  w[1] = 0.0000000000
  w[2] = 0.0000000000
  w[3] = 0.0000000000
  w[4] = 0.0000000000
  w[5] = 0.0000000000
  w[6] = 0.0000000000
  w[7] = 0.0000000000
  w[8] = 0.0000000000
  w[9] = 0.0000000000
  w[10] = 0.0000000000
  w[11] = 0.0000000000
  w[12] = 0.0000000000
  w[13] = 0.0000000000
  w[14] = 0.0000000000
  w[15] = 0.0000000000
  w[16] = 0.0000000000
  w[17] = 0.0000000000
  w[18] = 0.0000000000
  w[19] = 0.0000000000
  w[20] = 0.0000000000

L1 Norm: 0.0000000000

================================================================================
H2 Complete Weights and Bias
================================================================================
Description: Class 3 vs Class {1, 2}

Intercept (b): 1.0000000000

Weight vector (w) - 21 features:
  w[0] = 0.0000000000
  w[1] = 0.0000000000
  w[2] = 0.0000000000
  w[3] = 0.0000000000
  w[4] = 0.0000000000
  w[5] = 0.0000000000
  w[6] = 0.0000000000
  w[7] = 0.0000000000
  w[8] = 0.0000000000
  w[9] = 0.0000000000
  w[10] = 0.0000000000
  w[11] = 0.0000000000
  w[12] = 0.0000000000
  w[13] = 0.0000000000
  w[14] = 0.0000000000
  w[15] = 0.0000000000
  w[16] = 0.0000000000
  w[17] = 0.0000000000
  w[18] = 0.0000000000
  w[19] = 0.0000000000
  w[20] = 0.0000000000

L1 Norm: 0.0000000000

================================================================================
Training Set Evaluation
================================================================================


============================================================
Evaluation Results
============================================================

Total Accuracy: 0.9253

Per-Class Accuracy:
  Class 1: 0.0000
  Class 2: 0.0000
  Class 3: 1.0000

Class Distribution:
  Class 1: 14 samples
  Class 2: 29 samples
  Class 3: 533 samples

Confusion Matrix:
     Pred 1  Pred 2  Pred 3
True 1:     0       0      14
True 2:     0       0      29
True 3:     0       0     533
============================================================

================================================================================
Test Set Evaluation
================================================================================


============================================================
Evaluation Results
============================================================

Total Accuracy: 0.9236

Per-Class Accuracy:
  Class 1: 0.0000
  Class 2: 0.0000
  Class 3: 1.0000

Class Distribution:
  Class 1: 3 samples
  Class 2: 8 samples
  Class 3: 133 samples

Confusion Matrix:
     Pred 1  Pred 2  Pred 3
True 1:     0       0       3
True 2:     0       0       8
True 3:     0       0     133
============================================================

================================================================================
Test Complete!
================================================================================
Training Duration: 0:00:06.865563
Training Accuracy: 0.9253
Test Accuracy: 0.9236
Log saved to: /home/bs10081/Developer/hcesvm/results/test3_Thyroid_20260210_193735.log
================================================================================
