================================================================================
Hierarchical CE-SVM - TEST3 Strategy
Dataset: TAE
Timestamp: 2026-02-10 19:35:51
================================================================================

Training data:
  Class 1: 39 samples
  Class 2: 40 samples
  Class 3: 41 samples
  Features: 5

================================================================================
Model Parameters
================================================================================
  C_hyper: 1.0
  epsilon: 0.0001
  M: 1000.0
  time_limit: 1800
  mip_gap: 0.0001
  threads: 0
  verbose: True
  enable_selection: True
  feat_upper_bound: 1000
  feat_lower_bound: 1e-07

================================================================================
Training Hierarchical Classifier - TEST3 Strategy
================================================================================

Test3 Strategy:
  H1: {minority, medium} vs majority
  H2: minority vs medium
  Sample-weighted objective: -(1/s+)·l+ - (1/s-)·l-

============================================================
Training Hierarchical CE-SVM (Strategy: test3)
============================================================
Class 1: 39 samples
Class 2: 40 samples
Class 3: 41 samples
Features: 5

Dynamic Class Roles:
  Majority:  Class 3 (41 samples)
  Medium:    Class 2 (40 samples)
  Minority:  Class 1 (39 samples)

============================================================
Training H1: Class {2, 3} (+1) vs Class 1 (-1)
============================================================
H1 Training samples: 120
  Positive (+1): 81 samples
  Negative (-1): 39 samples
  Class weight: balanced
  Accuracy mode: both

Set parameter TimeLimit to value 1800
Set parameter MIPGap to value 0.0001
Set parameter OutputFlag to value 1
Set parameter Threads to value 0
Gurobi Optimizer version 13.0.1 build v13.0.1rc0 (linux64 - "Ubuntu 24.04.3 LTS")

CPU model: AMD Ryzen 9 9900X 12-Core Processor, instruction set [SSE2|AVX|AVX2|AVX512]
Thread count: 20 physical cores, 20 logical processors, using up to 20 threads

Non-default parameters:
TimeLimit  1800

Optimize a model with 852 rows, 498 columns and 3032 nonzeros (Min)
Model fingerprint: 0x30dad648
Model has 372 linear objective coefficients
Variable types: 133 continuous, 365 integer (365 binary)
Coefficient statistics:
  Matrix range     [1e-07, 1e+03]
  Objective range  [1e-02, 1e+00]
  Bounds range     [1e+00, 1e+00]
  RHS range        [1e+00, 2e+02]

Found heuristic solution: objective 273.1675758
Presolve removed 217 rows and 127 columns
Presolve time: 0.00s
Presolved: 635 rows, 371 columns, 2270 nonzeros
Variable types: 11 continuous, 360 integer (270 binary)

Root relaxation: objective 1.570646e-01, 257 iterations, 0.00 seconds (0.00 work units)

    Nodes    |    Current Node    |     Objective Bounds      |     Work
 Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time

     0     0    0.15706    0   90  273.16758    0.15706   100%     -    0s
H    0     0                      77.9876543    0.15706   100%     -    0s
     0     0    1.27022    0  182   77.98765    1.27022  98.4%     -    0s
     0     0    1.88480    0  201   77.98765    1.88480  97.6%     -    0s
     0     0    1.96201    0  201   77.98765    1.96201  97.5%     -    0s
     0     0    6.22532    0  188   77.98765    6.22532  92.0%     -    0s
     0     0    6.42759    0  202   77.98765    6.42759  91.8%     -    0s
     0     0    6.43259    0  202   77.98765    6.43259  91.8%     -    0s
     0     0   10.42337    0  189   77.98765   10.42337  86.6%     -    0s
     0     0   10.65090    0  195   77.98765   10.65090  86.3%     -    0s
     0     0   10.72684    0  196   77.98765   10.72684  86.2%     -    0s
     0     0   10.72984    0  196   77.98765   10.72984  86.2%     -    0s
     0     0   12.33471    0  210   77.98765   12.33471  84.2%     -    0s
     0     0   12.39869    0  218   77.98765   12.39869  84.1%     -    0s
     0     0   12.40353    0  208   77.98765   12.40353  84.1%     -    0s
     0     0   12.40570    0  209   77.98765   12.40570  84.1%     -    0s
     0     0   12.58510    0  213   77.98765   12.58510  83.9%     -    0s
     0     0   12.59337    0  214   77.98765   12.59337  83.9%     -    0s
     0     0   12.59647    0  218   77.98765   12.59647  83.8%     -    0s
     0     0   12.60537    0  214   77.98765   12.60537  83.8%     -    0s
     0     0   12.60703    0  214   77.98765   12.60703  83.8%     -    0s
     0     0   12.60703    0  214   77.98765   12.60703  83.8%     -    0s
     0     2   12.60752    0  214   77.98765   12.60752  83.8%     -    0s
 33360 15094   67.27579   43  176   77.98765   54.85635  29.7%  36.5    5s
 70409 24172   68.40850   46  214   77.98765   60.78238  22.1%  46.0   10s
 70541 24260   75.22754   43  251   77.98765   61.39715  21.3%  45.9   15s
 79906 25843   69.92162   47  254   77.98765   67.24229  13.8%  54.5   20s
 94212 26958   76.59035   65  222   77.98765   68.83550  11.7%  62.6   25s
 114758 26621   74.33333   56  255   77.98765   70.41779  9.71%  71.8   30s
 132276 24918   76.75054   60  181   77.98765   71.32279  8.55%  78.7   35s
 149480 23456   77.40391   61  207   77.98765   72.19665  7.43%  85.6   40s
 164975 23997   75.56967   55  254   77.98765   72.88176  6.55%  91.3   45s
 178992 23065   76.75217   60  270   77.98765   73.60687  5.62%  96.9   50s
 192070 20190   77.26721   54  163   77.98765   74.33402  4.68%   102   55s
 199573 16231     cutoff   60        77.98765   74.79343  4.10%   106   60s
 212983  4713     cutoff   54        77.98765   76.32064  2.14%   110   65s

Cutting planes:
  Learned: 1
  Gomory: 61
  Cover: 205
  Dual implied bound: 2
  MIR: 346
  StrongCG: 10
  Flow cover: 408
  GUB cover: 31
  Inf proof: 191
  Zero half: 3
  Relax-and-lift: 13

Explored 219907 nodes (23831869 simplex iterations) in 66.17 seconds (202.72 work units)
Thread count was 20 (of 20 available processors)

Solution count 2: 77.9877 273.168 

Optimal solution found (tolerance 1.00e-04)
Best objective 7.798765432099e+01, best bound 7.798765432099e+01, gap 0.0000%

H1 Solution:
  Weights (w): [0. 0. 0. 0. 0.]
  Intercept (b): 1.0
  Objective: 77.987654
  Selected features: 5/5
  L1 norm: 0.000000
  Positive accuracy lb: 1.0000
  Negative accuracy lb: 0.0000

============================================================
Training H2: Class 3 (+1) vs Class {1, 2} (-1)
============================================================
H2 Training samples: 120
  Positive (+1): 41 samples
  Negative (-1): 79 samples
  Class weight: balanced
  Accuracy mode: both

Set parameter TimeLimit to value 1800
Set parameter MIPGap to value 0.0001
Set parameter OutputFlag to value 1
Set parameter Threads to value 0
Gurobi Optimizer version 13.0.1 build v13.0.1rc0 (linux64 - "Ubuntu 24.04.3 LTS")

CPU model: AMD Ryzen 9 9900X 12-Core Processor, instruction set [SSE2|AVX|AVX2|AVX512]
Thread count: 20 physical cores, 20 logical processors, using up to 20 threads

Non-default parameters:
TimeLimit  1800

Optimize a model with 852 rows, 498 columns and 3032 nonzeros (Min)
Model fingerprint: 0x0e3c3e61
Model has 372 linear objective coefficients
Variable types: 133 continuous, 365 integer (365 binary)
Coefficient statistics:
  Matrix range     [1e-07, 1e+03]
  Objective range  [1e-02, 1e+00]
  Bounds range     [1e+00, 1e+00]
  RHS range        [1e+00, 2e+02]

Presolve removed 210 rows and 123 columns
Presolve time: 0.00s
Presolved: 642 rows, 375 columns, 2290 nonzeros
Variable types: 11 continuous, 364 integer (273 binary)
Found heuristic solution: objective 360.0000000
Found heuristic solution: objective 359.0000000
Found heuristic solution: objective 119.9629515

Root relaxation: objective 1.680003e-01, 280 iterations, 0.00 seconds (0.01 work units)

    Nodes    |    Current Node    |     Objective Bounds      |     Work
 Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time

     0     0    0.16800    0   93  119.96295    0.16800   100%     -    0s
H    0     0                      81.9873418    0.16800   100%     -    0s
     0     0    1.03407    0  243   81.98734    1.03407  98.7%     -    0s
     0     0    2.71324    0  216   81.98734    2.71324  96.7%     -    0s
     0     0    3.20962    0  229   81.98734    3.20962  96.1%     -    0s
     0     0    3.20962    0  220   81.98734    3.20962  96.1%     -    0s
     0     0    3.96327    0  233   81.98734    3.96327  95.2%     -    0s
     0     0    9.12741    0  227   81.98734    9.12741  88.9%     -    0s
     0     0    9.40372    0  240   81.98734    9.40372  88.5%     -    0s
     0     0    9.41666    0  241   81.98734    9.41666  88.5%     -    0s
     0     0    9.41966    0  241   81.98734    9.41966  88.5%     -    0s
     0     0   13.01678    0  218   81.98734   13.01678  84.1%     -    0s
     0     0   13.17802    0  215   81.98734   13.17802  83.9%     -    0s
     0     0   13.23531    0  224   81.98734   13.23531  83.9%     -    0s
     0     0   13.27332    0  225   81.98734   13.27332  83.8%     -    0s
     0     0   13.27698    0  225   81.98734   13.27698  83.8%     -    0s
     0     0   15.04552    0  240   81.98734   15.04552  81.6%     -    0s
     0     0   15.25368    0  230   81.98734   15.25368  81.4%     -    0s
     0     0   15.34553    0  235   81.98734   15.34553  81.3%     -    0s
     0     0   15.35699    0  233   81.98734   15.35699  81.3%     -    0s
     0     0   15.35726    0  236   81.98734   15.35726  81.3%     -    0s
     0     0   16.42493    0  212   81.98734   16.42493  80.0%     -    0s
     0     0   16.51855    0  220   81.98734   16.51855  79.9%     -    0s
     0     0   16.53898    0  219   81.98734   16.53898  79.8%     -    0s
     0     0   16.55840    0  217   81.98734   16.55840  79.8%     -    0s
     0     0   16.55875    0  217   81.98734   16.55875  79.8%     -    0s
     0     0   17.54897    0  217   81.98734   17.54897  78.6%     -    0s
     0     0   17.55104    0  225   81.98734   17.55104  78.6%     -    0s
     0     0   17.76243    0  213   81.98734   17.76243  78.3%     -    0s
     0     0   17.81808    0  225   81.98734   17.81808  78.3%     -    0s
     0     0   17.82391    0  221   81.98734   17.82391  78.3%     -    0s
     0     0   18.66810    0  236   81.98734   18.66810  77.2%     -    0s
     0     0   18.89695    0  238   81.98734   18.89695  77.0%     -    0s
     0     0   18.93508    0  206   81.98734   18.93508  76.9%     -    0s
     0     0   19.78042    0  229   81.98734   19.78042  75.9%     -    0s
     0     0   19.88058    0  232   81.98734   19.88058  75.8%     -    0s
     0     0   19.88819    0  215   81.98734   19.88819  75.7%     -    0s
     0     0   20.03074    0  239   81.98734   20.03074  75.6%     -    0s
     0     0   20.03511    0  241   81.98734   20.03511  75.6%     -    0s
     0     0   20.75536    0  228   81.98734   20.75536  74.7%     -    0s
     0     0   20.83404    0  233   81.98734   20.83404  74.6%     -    0s
     0     0   20.83884    0  231   81.98734   20.83884  74.6%     -    0s
     0     0   21.35401    0  246   81.98734   21.35401  74.0%     -    0s
     0     0   21.59989    0  234   81.98734   21.59989  73.7%     -    0s
     0     0   21.62657    0  233   81.98734   21.62657  73.6%     -    0s
     0     0   21.62807    0  233   81.98734   21.62807  73.6%     -    0s
     0     0   22.09045    0  245   81.98734   22.09045  73.1%     -    0s
     0     0   22.20981    0  247   81.98734   22.20981  72.9%     -    0s
     0     0   22.23560    0  252   81.98734   22.23560  72.9%     -    0s
     0     0   22.23943    0  260   81.98734   22.23943  72.9%     -    0s
     0     0   22.28376    0  260   81.98734   22.28376  72.8%     -    0s
     0     0   22.28376    0  260   81.98734   22.28376  72.8%     -    0s
     0     2   22.28376    0  260   81.98734   22.28376  72.8%     -    0s
H 3339  2083                      79.9807980   35.03147  56.2%  22.6    0s
H 4393  2403                      79.9802032   46.75756  41.5%  32.6    1s
H 8409  3526                      78.9759248   49.25517  37.6%  36.7    2s
H 8518  3563                      77.9759248   49.25517  36.8%  36.7    2s
 23423 11128   58.54931   33  283   77.97592   57.30733  26.5%  43.9    5s
H23994 10757                      76.9776873   58.48757  24.0%  46.0    5s
 40927 11833   76.80746   50  222   76.97769   65.07671  15.5%  58.6   10s
 64692 11636     cutoff   44        76.97769   68.72616  10.7%  69.1   15s
 78736 11842     cutoff   42        76.97769   70.56442  8.33%  75.6   20s
 90433  9484   76.26406   46  256   76.97769   72.37582  5.98%  83.3   25s
 104198     0     cutoff   44        76.97769   76.19171  1.02%  88.8   30s

Cutting planes:
  Gomory: 48
  Cover: 202
  Dual implied bound: 2
  Clique: 1
  MIR: 224
  StrongCG: 7
  Flow cover: 223
  GUB cover: 25
  Inf proof: 309
  Zero half: 2
  Relax-and-lift: 14

Explored 104925 nodes (9284633 simplex iterations) in 30.13 seconds (91.32 work units)
Thread count was 20 (of 20 available processors)

Solution count 10: 76.9777 76.9777 77.9759 ... 360

Optimal solution found (tolerance 1.00e-04)
Best objective 7.697768732245e+01, best bound 7.697768732245e+01, gap 0.0000%

H2 Solution:
  Weights (w): [-2.  0.  0. -2.  0.]
  Intercept (b): 7.0
  Objective: 76.977687
  Selected features: 5/5
  L1 norm: 4.000000
  Positive accuracy lb: 0.4878
  Negative accuracy lb: 0.8228

============================================================
Training Complete!
============================================================

Training completed in: 0:01:36.319864

================================================================================
Model Summary
================================================================================
Status: fitted
Strategy: test3
Features: 5

Class Roles:
  Majority: Class 3
  Medium:   Class 2
  Minority: Class 1

Classifier 1 (H1): Class {2, 3} vs Class 1
  Objective: 77.987654
  Selected Features: 5/5
  L1 Norm: 0.000000

Classifier 2 (H2): Class 3 vs Class {1, 2}
  Objective: 76.977687
  Selected Features: 5/5
  L1 Norm: 4.000000

================================================================================
H1 Complete Weights and Bias
================================================================================
Description: Class {2, 3} vs Class 1

Intercept (b): 1.0000000000

Weight vector (w) - 5 features:
  w[0] = 0.0000000000
  w[1] = 0.0000000000
  w[2] = 0.0000000000
  w[3] = 0.0000000000
  w[4] = 0.0000000000

L1 Norm: 0.0000000000

================================================================================
H2 Complete Weights and Bias
================================================================================
Description: Class 3 vs Class {1, 2}

Intercept (b): 7.0000000000

Weight vector (w) - 5 features:
  w[0] = -2.0000000000
  w[1] = 0.0000000000
  w[2] = 0.0000000000
  w[3] = -2.0000000000
  w[4] = 0.0000000000

L1 Norm: 4.0000000000

================================================================================
Training Set Evaluation
================================================================================


============================================================
Evaluation Results
============================================================

Total Accuracy: 0.4250

Per-Class Accuracy:
  Class 1: 0.0000
  Class 2: 0.7750
  Class 3: 0.4878

Class Distribution:
  Class 1: 39 samples
  Class 2: 40 samples
  Class 3: 41 samples

Confusion Matrix:
     Pred 1  Pred 2  Pred 3
True 1:     0      34       5
True 2:     0      31       9
True 3:     0      21      20
============================================================

================================================================================
Test Set Evaluation
================================================================================


============================================================
Evaluation Results
============================================================

Total Accuracy: 0.4839

Per-Class Accuracy:
  Class 1: 0.0000
  Class 2: 0.8000
  Class 3: 0.6364

Class Distribution:
  Class 1: 10 samples
  Class 2: 10 samples
  Class 3: 11 samples

Confusion Matrix:
     Pred 1  Pred 2  Pred 3
True 1:     0      10       0
True 2:     0       8       2
True 3:     0       4       7
============================================================

================================================================================
Test Complete!
================================================================================
Training Duration: 0:01:36.319864
Training Accuracy: 0.4250
Test Accuracy: 0.4839
Log saved to: /home/bs10081/Developer/hcesvm/results/test3_TAE_20260210_193551.log
================================================================================
